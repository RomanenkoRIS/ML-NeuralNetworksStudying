{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "angry-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms, utils, datasets\n",
    "\n",
    "sns.set(font_scale=1.4, style=\"whitegrid\")\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "verified-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x175abcef3f0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size_train = 64\n",
    "batch_size_test = 500\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "unlikely-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "appropriate-projector",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-47f6a1d00e70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not an iterator"
     ]
    }
   ],
   "source": [
    "next(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cognitive-argentina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enumerate at 0x175aee66dc0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([a, b],dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "rocky-bonus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "charitable-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fatty-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "abroad-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pacific-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "#             torch.save(network.state_dict(), '/results/model.pth')\n",
    "#             torch.save(optimizer.state_dict(), '/results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "affected-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "subtle-local",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-4ca24265f583>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "perfect-voluntary",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-a098dff32731>:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3089, Accuracy: 674/10000 (7%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.342404\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.279043\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.298765\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.277650\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.249324\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.220917\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.220687\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.191224\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.168834\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.126606\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.045601\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.884804\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.881673\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1.592906\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.558182\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.492340\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 1.404370\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 1.333422\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 1.249338\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 1.138170\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.186302\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 1.051915\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 1.024379\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.814084\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.882737\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.893821\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.909165\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.704662\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.935668\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.916787\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.853384\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.766440\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.674521\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.698457\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.585391\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.777994\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.638581\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.734270\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.858937\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.757073\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.785678\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.676699\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.607075\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.590273\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.680529\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.727835\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.556806\n",
      "\n",
      "Test set: Avg. loss: 0.2836, Accuracy: 9184/10000 (92%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.706068\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.655768\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.520403\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.601346\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.597274\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.545276\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.408805\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.605759\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.503479\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.516950\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.478709\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.621539\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.520779\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.562836\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.591260\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.523842\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.606701\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.577131\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.443957\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.531429\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.560254\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.606662\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.410915\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.517527\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.408630\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.389265\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.532099\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.460998\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.482606\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.521394\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.541034\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.494009\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.483835\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.366427\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.797196\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.341109\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.436459\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.369523\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.528977\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.429362\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.400773\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.370186\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.465334\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.351091\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.488228\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.314529\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.440963\n",
      "\n",
      "Test set: Avg. loss: 0.1801, Accuracy: 9460/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.349052\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.457741\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.409871\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.330222\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.464698\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.370584\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.412744\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.520493\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.351391\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.491733\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.436523\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.396514\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.449506\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.461745\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.448940\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.330906\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.435931\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.344393\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.514078\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.682895\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.315572\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.292644\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.325205\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.471931\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.477626\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.377498\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.376488\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.303786\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.308930\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.432522\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.417938\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.527693\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.353404\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.391416\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.369417\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.472521\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.372952\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.432875\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.354762\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.301607\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.311123\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.243291\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.311829\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.286389\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.333771\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.233497\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.557075\n",
      "\n",
      "Test set: Avg. loss: 0.1405, Accuracy: 9576/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.343976\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.413355\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.339734\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.376876\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.350695\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.452619\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.403385\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.341933\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.360251\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.274838\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.369850\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.297590\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.255866\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.234018\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.416961\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.401347\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.314716\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.473437\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.440181\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.342474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.457073\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.310122\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.300980\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.237695\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.388767\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.445845\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.371798\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.174642\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.337979\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.358524\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.360277\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.266667\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.328405\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.241522\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.292266\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.294562\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.223136\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.318862\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.255661\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.203619\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.230013\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.275809\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.358176\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.338890\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.254257\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.378453\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.378475\n",
      "\n",
      "Test set: Avg. loss: 0.1188, Accuracy: 9651/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.290874\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.221503\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.261776\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.224089\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.327784\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.361493\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.215923\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.287370\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.462274\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.413215\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.202565\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.226289\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.411990\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.305224\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.358870\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.242504\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.229725\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.297545\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.153418\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.223992\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.347342\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.237553\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.269213\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.354472\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.281406\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.247956\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.257497\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.214861\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.228377\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.268733\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.269722\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.260071\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.179022\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.289144\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.325841\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.275971\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.359244\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.399102\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.247620\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.242775\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.317627\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.255089\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.225064\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.278555\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.277969\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.237062\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.279783\n",
      "\n",
      "Test set: Avg. loss: 0.1006, Accuracy: 9677/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "appropriate-conditions",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scatter() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-61bb92a661c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'number of training examples seen'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: scatter() missing 1 required positional argument: 'y'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_losses, color='blue')\n",
    "plt.scatter(test_losses, color='red')\n",
    "# plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "# plt.ylabel('negative log likelihood loss')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "south-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig = plt.figure()\n",
    "# for i in range(1):\n",
    "#   plt.subplot(2,3,i+1)\n",
    "#   plt.tight_layout()\n",
    "#   plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "#   plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "#   plt.xticks([])\n",
    "#   plt.yticks([])\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "boring-olive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "grateful-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(batch_size):\n",
    "        \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                                   transform=torchvision.transforms.Compose([\n",
    "                                       torchvision.transforms.ToTensor(),\n",
    "                                       torchvision.transforms.Normalize(\n",
    "                                           (0.1307,), (0.3081,))\n",
    "                                   ])),\n",
    "        batch_size=batch_size_train, shuffle=True)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                                   transform=torchvision.transforms.Compose([\n",
    "                                       torchvision.transforms.ToTensor(),\n",
    "                                       torchvision.transforms.Normalize(\n",
    "                                           (0.1307,), (0.3081,))\n",
    "                                   ])),\n",
    "        batch_size=batch_size_test, shuffle=True)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "final-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    valid_accuracies = []\n",
    "    \n",
    "    #train part\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        loss_sum = 0\n",
    "        for xb, yb in tqdm(train_dl):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            \n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss_sum += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        train_losses.append(loss_sum/len(train_dl))\n",
    "        \n",
    "        model.eval()\n",
    "        loss_sum = 0\n",
    "        correct = 0\n",
    "        num = 0\n",
    "        \n",
    "        #test part\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for xb, yb in tqdm(valid_dl):\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                \n",
    "                prob = model(xb)\n",
    "                loss_sum += loss_func(probs, yb).item()\n",
    "                \n",
    "                _, preds = torch.max(probs, axis =-1)\n",
    "                correct +=(preds == yb).sum().item()\n",
    "                num += len(xb)\n",
    "                \n",
    "        val_losses.append(loss_sum/len(valid_dl))\n",
    "        valid_accuracies.append(correct/num)\n",
    "        \n",
    "    return train_losses, val_losses, valid_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "radio-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(train_losses, valid_losses, valid_accuracies):\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.plot(train_losses, lable='train loss')\n",
    "    plt.plot(valid_losses, lable='valid loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    plt.xlale('epoch')\n",
    "    plt.plot(valid_accuracies, lable='valid accuracy')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "attached-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.hidden1 = nn.Linear(28*28, 500)        \n",
    "        self.output = nn.Linear(500, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.hidden1(x)\n",
    "        x = self.activation(x)         \n",
    "        x = self.output(x) \n",
    "        output = self.softmax(x)\n",
    "        return output        \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fossil-beauty",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2011-3\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\cuda\\__init__.py:81: UserWarning: \n",
      "    Found GPU0 NVIDIA GeForce GTX 650 Ti which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696a5f3d9890473c9adbf0e2a72af613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 dim 1 must match mat2 dim 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-563006000ec9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mget_dataloaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplot_trainig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-a3f2ee1829a1>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, model, loss_func, opt, train_dl, valid_dl)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mloss_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-d13851930564>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
     ]
    }
   ],
   "source": [
    "model = Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "info = fit(10, model, criterion, optimizer, *get_dataloaders(4))\n",
    "plot_trainig(*info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-firmware",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-incident",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
